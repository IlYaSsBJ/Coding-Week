{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE5FD7A8CMU0Rh6dIOlwDs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlYaSsBJ/Coding-Week/blob/main/XGboost_model_TESTING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET Winsoring cleaning**"
      ],
      "metadata": {
        "id": "jtZFXK1-YOot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import datetime\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Charger le dataset\n",
        "file_path = r\"C:\\Users\\doham\\Desktop\\ObesityDataSet_raw_and_data_originale.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes du dataset\n",
        "print(df.head())\n",
        "print(df.shape)\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "# Vérification des valeurs manquantes\n",
        "print(\"Valeurs manquantes par colonne:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Visualisation des outliers\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.boxplot(data=df.select_dtypes(include=['number']))\n",
        "plt.xticks(rotation=90)  # Rotation des labels\n",
        "plt.show()\n",
        "\n",
        "# Copie du dataset complet pour transformation\n",
        "df_transformed = df.copy()\n",
        "\n",
        "# Appliquer le Winsorizing sur les colonnes sélectionnées\n",
        "for col in [\"Weight\", \"Age\"]:\n",
        "    if col in df_transformed.columns:\n",
        "        df_transformed[col] = winsorize(df_transformed[col], limits=[0.05, 0.05])  # Tronque les 5% inférieurs et supérieurs\n",
        "\n",
        "# Générer un nom de fichier unique basé sur la date et l'heure\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_path = fr\"C:\\Users\\doham\\Desktop\\dhd_transformed_{timestamp}.csv\"\n",
        "df_transformed.to_csv(output_path, index=False)\n",
        "print(f\"Dataset transformé sauvegardé à : {output_path}\")\n",
        "\n",
        "# Visualisation de la distribution des classes\n",
        "df[\"NObeyesdad\"].value_counts().plot(kind=\"bar\", color=\"skyblue\")\n",
        "plt.title(\"Distribution des Classes\")\n",
        "plt.xlabel(\"Classes d'Obésité\")\n",
        "plt.ylabel(\"Nombre d'Exemples\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j-KXiCXuYNql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset structure Before and after cleaning**"
      ],
      "metadata": {
        "id": "Od_uV715YWi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import datetime\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Charger le dataset\n",
        "file_path = r\"C:\\Users\\doham\\Desktop\\ObesityDataSet_raw_and_data_originale.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes du dataset\n",
        "print(df.head())\n",
        "print(df.shape)\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "# Vérification des valeurs manquantes\n",
        "print(\"Valeurs manquantes par colonne:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Visualisation des outliers AVANT Winsorizing\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.boxplot(data=df.select_dtypes(include=['number']))\n",
        "plt.title(\"Distribution des données AVANT Winsorizing\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "# Copie du dataset complet pour transformation\n",
        "df_transformed = df.copy()\n",
        "\n",
        "# Appliquer le Winsorizing sur les colonnes sélectionnées\n",
        "for col in [\"Weight\", \"Age\"]:\n",
        "    if col in df_transformed.columns:\n",
        "        df_transformed[col] = winsorize(df_transformed[col], limits=[0.05, 0.05])  # Tronque les 5% inférieurs et supérieurs\n",
        "\n",
        "# Visualisation des outliers APRÈS Winsorizing\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.boxplot(data=df_transformed.select_dtypes(include=['number']))\n",
        "plt.title(\"Distribution des données APRÈS Winsorizing\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "# Générer un nom de fichier unique basé sur la date et l'heure\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_path = fr\"C:\\Users\\doham\\Desktop\\dhd_transformed_{timestamp}.csv\"\n",
        "df_transformed.to_csv(output_path, index=False)\n",
        "print(f\"Dataset transformé sauvegardé à : {output_path}\")\n",
        "\n",
        "# Visualisation de la distribution des classes\n",
        "df[\"NObeyesdad\"].value_counts().plot(kind=\"bar\", color=\"skyblue\")\n",
        "plt.title(\"Distribution des Classes\")\n",
        "plt.xlabel(\"Classes d'Obésité\")\n",
        "plt.ylabel(\"Nombre d'Exemples\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EZ8Xk34dYsDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNDERSAMPLING METHOD APPLIED ON bOTH DATASETS**"
      ],
      "metadata": {
        "id": "dtTU0gY_Y-IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "def load_and_prepare_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Encoder la variable cible\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[\"NObeyesdad\"] = label_encoder.fit_transform(df[\"NObeyesdad\"])\n",
        "\n",
        "    # Encoder les variables catégoriques avec One-Hot Encoding\n",
        "    df = pd.get_dummies(df, columns=[\"Gender\", \"family_history_with_overweight\", \"FAVC\",\n",
        "                                     \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"], drop_first=True)\n",
        "\n",
        "    # Séparer X et y\n",
        "    X = df.drop(columns=[\"NObeyesdad\"])\n",
        "    y = df[\"NObeyesdad\"]\n",
        "\n",
        "    return X, y, label_encoder\n",
        "\n",
        "def undersampling_and_evaluate(file_path, model_name=\"XGBoost\"):\n",
        "    # Charger les données\n",
        "    X, y, label_encoder = load_and_prepare_data(file_path)\n",
        "\n",
        "    # Diviser en train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "    undersampler = RandomUnderSampler(sampling_strategy=\"auto\", random_state=42)\n",
        "    X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(f\"Training Set Size after Undersampling: {X_train_under.shape}\")\n",
        "    print(f\"Testing Set Size: {X_test.shape}\")\n",
        "\n",
        "    model = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
        "    model.fit(X_train_under, y_train_under)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"\\nClassification Report for {model_name} ({file_path.split('/')[-1]}):\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nModel Accuracy for {model_name} ({file_path.split('/')[-1]}): {accuracy:.4f}\")\n",
        "\n",
        "    y_proba = model.predict_proba(X_test)\n",
        "\n",
        "    y_test_bin = label_binarize(y_test, classes=np.arange(len(label_encoder.classes_)))\n",
        "\n",
        "    auc_score = roc_auc_score(y_test_bin, y_proba, multi_class=\"ovr\")\n",
        "\n",
        "    print(f\"ROC-AUC Score For {model_name} ({file_path.split('/')[-1]}): {auc_score:.4f}\")\n",
        "\n",
        "undersampling_and_evaluate(r\"C:\\Users\\doham\\Desktop\\age+weight_done.csv\", \"XGBoost\")\n",
        "undersampling_and_evaluate(r\"C:\\Users\\doham\\Desktop\\dhd_transformed_winsoring.csv\", \"XGBoost\")\n"
      ],
      "metadata": {
        "id": "mhorV9HKZHD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OVERSAMPLING METHOD APPLIED ON bOTH DATASETS**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fp986CyMZKPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def load_and_prepare_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[\"NObeyesdad\"] = label_encoder.fit_transform(df[\"NObeyesdad\"])\n",
        "    df = pd.get_dummies(df, columns=[\"Gender\", \"family_history_with_overweight\", \"FAVC\",\n",
        "                                     \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"], drop_first=True)\n",
        "    X = df.drop(columns=[\"NObeyesdad\"])\n",
        "    y = df[\"NObeyesdad\"]\n",
        "    return X, y, label_encoder\n",
        "\n",
        "def oversampling_and_evaluate(file_path, model_name=\"XGBoost\"):\n",
        "    X, y, label_encoder = load_and_prepare_data(file_path)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "    oversampler = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
        "    X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)\n",
        "    print(f\"Training Set Size after Oversampling: {X_train_over.shape}\")\n",
        "    print(f\"Testing Set Size: {X_test.shape}\")\n",
        "    model = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
        "    model.fit(X_train_over, y_train_over)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\nClassification Report for {model_name} ({file_path.split('/')[-1]}):\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nModel Accuracy for {model_name} ({file_path.split('/')[-1]}): {accuracy:.4f}\")\n",
        "    y_proba = model.predict_proba(X_test)\n",
        "    y_test_bin = label_binarize(y_test, classes=np.arange(len(label_encoder.classes_)))\n",
        "    auc_score = roc_auc_score(y_test_bin, y_proba, multi_class=\"ovr\")\n",
        "    print(f\"ROC-AUC Score For {model_name} ({file_path.split('/')[-1]}): {auc_score:.4f}\")\n",
        "\n",
        "oversampling_and_evaluate(r\"C:\\Users\\doham\\Desktop\\age+weight_done.csv\", \"XGBoost\")\n",
        "oversampling_and_evaluate(r\"C:\\Users\\doham\\Desktop\\dhd_transformed_winsoring.csv\", \"XGBoost\")\n"
      ],
      "metadata": {
        "id": "jSK0BVDAZJ71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classweights METHOD APPLIED ON bOTH DATASETS**"
      ],
      "metadata": {
        "id": "LPpO50xdZSpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "def load_and_prepare_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[\"NObeyesdad\"] = label_encoder.fit_transform(df[\"NObeyesdad\"])\n",
        "    df = pd.get_dummies(df, columns=[\"Gender\", \"family_history_with_overweight\", \"FAVC\",\n",
        "                                     \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"], drop_first=True)\n",
        "    X = df.drop(columns=[\"NObeyesdad\"])\n",
        "    y = df[\"NObeyesdad\"]\n",
        "    return X, y, label_encoder\n",
        "\n",
        "def class_weights_and_evaluate(file_path, model_name=\"XGBoost\"):\n",
        "    X, y, label_encoder = load_and_prepare_data(file_path)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "    weights_dict = {c: w for c, w in zip(np.unique(y_train), class_weights)}\n",
        "    print(f\"Training Set Size: {X_train.shape}\")\n",
        "    print(f\"Testing Set Size: {X_test.shape}\")\n",
        "    model = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
        "    model.fit(X_train, y_train, sample_weight=np.array([weights_dict[i] for i in y_train]))\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\nClassification Report for {model_name} ({file_path.split('/')[-1]}):\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nModel Accuracy for {model_name} ({file_path.split('/')[-1]}): {accuracy:.4f}\")\n",
        "    y_proba = model.predict_proba(X_test)\n",
        "    y_test_bin = label_binarize(y_test, classes=np.arange(len(label_encoder.classes_)))\n",
        "    auc_score = roc_auc_score(y_test_bin, y_proba, multi_class=\"ovr\")\n",
        "    print(f\"ROC-AUC Score For {model_name} ({file_path.split('/')[-1]}): {auc_score:.4f}\")\n",
        "\n",
        "class_weights_and_evaluate(r\"C:\\Users\\doham\\Desktop\\age+weight_done.csv\", \"XGBoost\")\n",
        "class_weights_and_evaluate(r\"C:\\Users\\doham\\Desktop\\dhd_transformed_winsoring.csv\", \"XGBoost\")"
      ],
      "metadata": {
        "id": "KKgqWDQbZeBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST ROC-AUC**"
      ],
      "metadata": {
        "id": "REDuomSgZuxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def load_and_prepare_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Encoder la variable cible\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[\"NObeyesdad\"] = label_encoder.fit_transform(df[\"NObeyesdad\"])\n",
        "\n",
        "    # Encoder les variables catégoriques avec One-Hot Encoding\n",
        "    df = pd.get_dummies(df, columns=[\"Gender\", \"family_history_with_overweight\", \"FAVC\",\n",
        "                                     \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"], drop_first=True)\n",
        "\n",
        "    # Séparer X et y\n",
        "    X = df.drop(columns=[\"NObeyesdad\"])\n",
        "    y = df[\"NObeyesdad\"]\n",
        "\n",
        "    # Diviser en train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, y, label_encoder\n",
        "\n",
        "\n",
        "def train_and_evaluate_roc_auc(file_path, model_name=\"XGBoost\"):\n",
        "    # Charger les données\n",
        "    X_train, X_test, y_train, y_test, y, label_encoder = load_and_prepare_data(file_path)\n",
        "\n",
        "    # Entraîner le modèle XGBoost\n",
        "    model = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prédire les probabilités\n",
        "    y_proba = model.predict_proba(X_test)\n",
        "\n",
        "    # Binariser les classes pour ROC-AUC multi-classe\n",
        "    y_test_bin = label_binarize(y_test, classes=np.arange(len(label_encoder.classes_)))\n",
        "\n",
        "    # Calcul du ROC-AUC global\n",
        "    auc_score = roc_auc_score(y_test_bin, y_proba, multi_class=\"ovr\")\n",
        "\n",
        "    # Afficher le résultat\n",
        "    print(f\"ROC-AUC Score For {model_name} ({file_path.split('/')[-1]}): {auc_score:.4f}\")\n",
        "\n",
        "\n",
        "train_and_evaluate_roc_auc(r\"C:\\Users\\doham\\Desktop\\age+weight_done.csv\", \"XGBoost\")\n",
        "train_and_evaluate_roc_auc(r\"C:\\Users\\doham\\Desktop\\dhd_transformed_winsoring.csv\", \"XGBoost\")"
      ],
      "metadata": {
        "id": "vXBvLJv6Zt1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MATRICES DE CONFUSION**"
      ],
      "metadata": {
        "id": "C-99S71oaPMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "def load_and_prepare_data(file_path):\n",
        "    # Charger le dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Encoder la variable cible (y)\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[\"NObeyesdad\"] = label_encoder.fit_transform(df[\"NObeyesdad\"])\n",
        "\n",
        "    # Encoder les variables catégoriques avec One-Hot Encoding\n",
        "    df = pd.get_dummies(df, columns=[\"Gender\", \"family_history_with_overweight\", \"FAVC\",\n",
        "                                     \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"], drop_first=True)\n",
        "\n",
        "\n",
        "    X = df.drop(columns=[\"NObeyesdad\"])\n",
        "    y = df[\"NObeyesdad\"]\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, label_encoder\n",
        "\n",
        "\n",
        "file_path1 = r\"C:\\Users\\doham\\Desktop\\age+weight_done.csv\"\n",
        "X_train1, X_test1, y_train1, y_test1, label_encoder1 = load_and_prepare_data(file_path1)\n",
        "\n",
        "model1 = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
        "model1.fit(X_train1, y_train1)\n",
        "y_pred1 = model1.predict(X_test1)\n",
        "\n",
        "\n",
        "file_path2 = r\"C:\\Users\\doham\\Desktop\\dhd_transformed_winsoring.csv\"\n",
        "X_train2, X_test2, y_train2, y_test2, label_encoder2 = load_and_prepare_data(file_path2)\n",
        "\n",
        "model2 = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
        "model2.fit(X_train2, y_train2)\n",
        "y_pred2 = model2.predict(X_test2)\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, label_encoder, dataset_name):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.title(f\"Confusion Matrix - {dataset_name}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_confusion_matrix(y_test1, y_pred1, label_encoder1, \"age+weight_done.csv\")\n",
        "plot_confusion_matrix(y_test2, y_pred2, label_encoder2, \"dhd_transformed_winsoring.csv\")"
      ],
      "metadata": {
        "id": "NsZqqLBjaTbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CODE FINAL** **& SHAP**"
      ],
      "metadata": {
        "id": "WG53seM5Z2E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "from flask import Flask, request, jsonify\n",
        "import requests\n",
        "\n",
        "def load_and_prepare_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[\"NObeyesdad\"] = label_encoder.fit_transform(df[\"NObeyesdad\"])\n",
        "    df = pd.get_dummies(df, columns=[\"Gender\", \"family_history_with_overweight\", \"FAVC\",\n",
        "                                     \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"], drop_first=True)\n",
        "    X = df.drop(columns=[\"NObeyesdad\"])\n",
        "    y = df[\"NObeyesdad\"]\n",
        "    return X, y, label_encoder\n",
        "\n",
        "file_path = r\"C:\\Users\\doham\\Desktop\\dhd_transformed_winsoring.csv\"\n",
        "X, y, label_encoder = load_and_prepare_data(file_path)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "weights_dict = {c: w for c, w in zip(np.unique(y_train), class_weights)}\n",
        "\n",
        "params = {\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"n_estimators\": [100, 200, 300]\n",
        "}\n",
        "\n",
        "xgb = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
        "\n",
        "grid = GridSearchCV(xgb, param_grid=params, cv=5, scoring=\"roc_auc_ovr\", n_jobs=-1)\n",
        "grid.fit(X_train, y_train, sample_weight=np.array([weights_dict[i] for i in y_train]))\n",
        "\n",
        "print(\"Meilleurs hyperparamètres :\", grid.best_params_)\n",
        "\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_proba = grid.best_estimator_.predict_proba(X_test)\n",
        "y_test_bin = label_binarize(y_test, classes=np.arange(len(label_encoder.classes_)))\n",
        "auc_score = roc_auc_score(y_test_bin, y_proba, multi_class=\"ovr\")\n",
        "print(f\"ROC-AUC Score: {auc_score:.4f}\")\n",
        "\n",
        "explainer = shap.TreeExplainer(grid.best_estimator_)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values_selected = shap_values[0]\n",
        "else:\n",
        "    shap_values_selected = shap_values\n",
        "\n",
        "shap.summary_plot(shap_values_selected, X_test)\n",
        "\n",
        "\n",
        "\n",
        "file_path = r\"C:\\Users\\doham\\Desktop\\dhd_transformed_winsoring.csv\"\n",
        "X, y, label_encoder = load_and_prepare_data(file_path)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "weights_dict = {c: w for c, w in zip(np.unique(y_train), class_weights)}\n",
        "\n",
        "xgb = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=np.array([weights_dict[i] for i in y_train]))\n",
        "\n",
        "joblib.dump(xgb, \"xgboost_model.pkl\")\n",
        "print(\"Modèle sauvegardé avec succès !\")\n"
      ],
      "metadata": {
        "id": "sMWbta8qZ6QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGboost Model** **Training**"
      ],
      "metadata": {
        "id": "55f2h4QQVzVA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xv0D6sdUUc1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Charger les données\n",
        "file_path = r\"C:\\Users\\doham\\Desktop\\dhd_transformed_winsoring.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Encoder la colonne cible\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"NObeyesdad\"] = label_encoder.fit_transform(df[\"NObeyesdad\"])\n",
        "\n",
        "# Transformer les variables catégoriques\n",
        "df = pd.get_dummies(df, columns=[\"Gender\", \"family_history_with_overweight\", \"FAVC\",\n",
        "                                 \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"], drop_first=True)\n",
        "\n",
        "# Séparer les données\n",
        "X = df.drop(columns=[\"NObeyesdad\"])\n",
        "y = df[\"NObeyesdad\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Calculer les poids des classes\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "weights_dict = {c: w for c, w in zip(np.unique(y_train), class_weights)}\n",
        "\n",
        "# Entraîner le modèle XGBoost\n",
        "model = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
        "model.fit(X_train, y_train, sample_weight=np.array([weights_dict[i] for i in y_train]))\n",
        "\n",
        "# Sauvegarder le modèle\n",
        "joblib.dump(model, \"xgboost_model.pkl\")\n",
        "print(\" Modèle XGBoost Entraîné et Sauvegardé !\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APP**"
      ],
      "metadata": {
        "id": "sDCgBbjIWT86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "st.set_page_config(page_title=\"Outil Médical de Diagnostic de l'Obésité\", layout=\"wide\")\n",
        "st.title(\"🩺 **Outil Médical de Diagnostic de l'Obésité**\")\n",
        "st.divider()\n",
        "\n",
        "model = joblib.load(\"xgboost_model.pkl\")\n",
        "\n",
        "expected_features = [\n",
        "    \"Age\", \"Height\", \"Weight\", \"FCVC\", \"NCP\", \"CH2O\", \"FAF\", \"TUE\",\n",
        "    \"Gender_Male\", \"family_history_with_overweight_yes\", \"FAVC_yes\",\n",
        "    \"CAEC_Frequently\", \"CAEC_Sometimes\", \"CAEC_no\", \"SMOKE_yes\", \"SCC_yes\",\n",
        "    \"CALC_Frequently\", \"CALC_Sometimes\", \"CALC_no\", \"MTRANS_Bike\",\n",
        "    \"MTRANS_Motorbike\", \"MTRANS_Public_Transportation\", \"MTRANS_Walking\"\n",
        "]\n",
        "\n",
        "st.subheader(\" **Saisie des Informations du Patient**\")\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    age = st.slider(\"**Âge du Patient**\", 10, 100, 25)\n",
        "    height = st.slider(\"**Taille (m)**\", 1.0, 2.5, 1.75)\n",
        "    weight = st.slider(\"**Poids (kg)**\", 30, 200, 70)\n",
        "    activity = st.selectbox(\"**Activité Physique**\", [\"Faible\", \"Moyenne\", \"Élevée\"])\n",
        "\n",
        "with col2:\n",
        "    food_intake = st.selectbox(\"**Consommation d'Aliments Caloriques**\", [\"Rare\", \"Modérée\", \"Fréquente\"])\n",
        "    vegetables = st.slider(\"**Consommation de Légumes (fréquence sur 5)**\", 0, 5, 2)\n",
        "    water_intake = st.slider(\"**Consommation d'Eau (L/jour)**\", 0, 5, 2)\n",
        "    smoking = st.selectbox(\"**Patient Fumeur ?**\", [\"Non\", \"Oui\"])\n",
        "\n",
        "\n",
        "if st.button(\" Réinitialiser les valeurs\"):\n",
        "    st.rerun()\n",
        "\n",
        "input_data = pd.DataFrame([[age, height, weight, activity, food_intake, vegetables, water_intake, smoking]],\n",
        "                          columns=[\"Age\", \"Height\", \"Weight\", \"Activity\", \"Food_Intake\", \"Vegetables\", \"Water_Intake\", \"Smoking\"])\n",
        "\n",
        "encoding_dict = {\n",
        "    \"Activity\": {\"Faible\": 0, \"Moyenne\": 1, \"Élevée\": 2},\n",
        "    \"Food_Intake\": {\"Rare\": 0, \"Modérée\": 1, \"Fréquente\": 2},\n",
        "    \"Smoking\": {\"Non\": 0, \"Oui\": 1}\n",
        "}\n",
        "\n",
        "for col, mapping in encoding_dict.items():\n",
        "    input_data[col] = input_data[col].map(mapping)\n",
        "\n",
        "for col in expected_features:\n",
        "    if col not in input_data.columns:\n",
        "        input_data[col] = 0\n",
        "\n",
        "input_data = input_data[expected_features]\n",
        "\n",
        "# === IMC ====\n",
        "def get_imc_obesity_level(imc):\n",
        "    if imc < 18.5:\n",
        "        return \"Poids Insuffisant\"\n",
        "    elif 18.5 <= imc < 25:\n",
        "        return \"Poids Normal\"\n",
        "    elif 25 <= imc < 30:\n",
        "        return \"Surpoids Niveau I\"\n",
        "    elif 30 <= imc < 35:\n",
        "        return \"Obésité Type I\"\n",
        "    elif 35 <= imc < 40:\n",
        "        return \"Obésité Type II\"\n",
        "    else:\n",
        "        return \"Obésité Type III\"\n",
        "\n",
        "obesity_levels = {\n",
        "    0: \"Poids Insuffisant\",\n",
        "    1: \"Poids Normal\",\n",
        "    2: \"Surpoids Niveau I\",\n",
        "    3: \"Surpoids Niveau II\",\n",
        "    4: \"Obésité Type I\",\n",
        "    5: \"Obésité Type II\",\n",
        "    6: \"Obésité Type III\"\n",
        "}\n",
        "\n",
        "\n",
        "obesity_info_messages = {\n",
        "    \"Poids Insuffisant\": \"⚠️ Le patient présente un poids insuffisant, ce qui peut causer des carences nutritionnelles et une fragilité osseuse.\",\n",
        "    \"Poids Normal\": \"✅ Le patient est dans une fourchette de poids normale. Maintenir une alimentation équilibrée et une activité physique régulière.\",\n",
        "    \"Surpoids Niveau I\": \"⚠️ Le patient est en surpoids. Il est recommandé d'améliorer l'activité physique et de surveiller l'alimentation.\",\n",
        "    \"Obésité Type I\": \"⚠️ Le patient présente une obésité modérée. Une consultation médicale est conseillée pour éviter les complications.\",\n",
        "    \"Obésité Type II\": \"⚠️ Obésité sévère. Un suivi médical est fortement recommandé pour prévenir les maladies cardiovasculaires et métaboliques.\",\n",
        "    \"Obésité Type III\": \"⚠️ Obésité morbide. Une prise en charge médicale urgente est nécessaire pour éviter des complications graves.\"\n",
        "}\n",
        "\n",
        "if st.button(\" **Analyser le Patient**\", key=\"prediction_button\"):\n",
        "    prediction = model.predict(input_data)[0]\n",
        "    predicted_obesity = obesity_levels[prediction]\n",
        "\n",
        "    # === IMC Calculus ===\n",
        "    imc = weight / (height ** 2)\n",
        "    imc_obesity = get_imc_obesity_level(imc)\n",
        "\n",
        "    # === Prediction ===\n",
        "\n",
        "    st.subheader(\" **Diagnostic Médical**\")\n",
        "    st.success(f\" **Classification du Modèle :** {predicted_obesity}\")\n",
        "    st.info(f\" **IMC Calculé :** {imc:.2f} → **Classification selon l'IMC :** {imc_obesity}\")\n",
        "\n",
        "    # === Medical Explanation ===\n",
        "    if st.checkbox(\" Voir les explications médicales détaillées\"):\n",
        "        st.warning(obesity_info_messages[predicted_obesity])\n",
        "\n",
        "    # === Doctor's feedback ===\n",
        "\n",
        "    st.subheader(\"🩺 **Validation Médicale et Feedback**\")\n",
        "    feedback = st.radio(\"Le diagnostic du modèle est-il correct ?\", (\"Oui\", \"Non\"), horizontal=True)\n",
        "\n",
        "    correction = None\n",
        "    if feedback == \"Non\":\n",
        "        st.warning(\"Sélectionnez la correction appropriée avant de soumettre.\")\n",
        "        correction = st.selectbox(\"**Correction Médicale :**\", list(obesity_levels.values()))\n",
        "\n",
        "    # === Submit feedback ===\n",
        "\n",
        "    if st.button(\" **Soumettre le Feedback**\", key=\"submit_feedback\"):\n",
        "        with st.spinner(\"Enregistrement du feedback...\"):\n",
        "            time.sleep(2)\n",
        "            if feedback == \"Oui\":\n",
        "                st.success(\" **Feedback soumis :** Le diagnostic est validé.\")\n",
        "            else:\n",
        "                if correction:\n",
        "                    with open(\"model_feedback.csv\", \"a\") as f:\n",
        "                        f.write(f\"{age},{height},{weight},{activity},{food_intake},{vegetables},{water_intake},{smoking},{correction}\\n\")\n",
        "                    st.success(f\" **Correction enregistrée :** Le modèle prendra en compte '{correction}' lors de la prochaine mise à jour.\")\n",
        "                else:\n",
        "                    st.error(\" **Erreur :** Veuillez sélectionner une correction avant de soumettre.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wUUGYlYHWRZw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}